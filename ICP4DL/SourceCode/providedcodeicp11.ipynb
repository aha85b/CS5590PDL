{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1icp11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNslsvqjqxzV",
        "outputId": "4e5ee024-93a1-462f-d915-5bb7d804158a"
      },
      "source": [
        "# Simple CNN model for CIFAR-10\n",
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.image_data_format()\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 227s 145ms/step - loss: 1.9725 - accuracy: 0.2745 - val_loss: 1.4394 - val_accuracy: 0.4817\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 228s 146ms/step - loss: 1.4410 - accuracy: 0.4829 - val_loss: 1.2295 - val_accuracy: 0.5607\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 229s 146ms/step - loss: 1.2344 - accuracy: 0.5582 - val_loss: 1.1424 - val_accuracy: 0.5910\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 1.1195 - accuracy: 0.6009 - val_loss: 1.0891 - val_accuracy: 0.6092\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 1.0243 - accuracy: 0.6401 - val_loss: 1.0296 - val_accuracy: 0.6325\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 0.9288 - accuracy: 0.6700 - val_loss: 1.0095 - val_accuracy: 0.6457\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.8631 - accuracy: 0.6952 - val_loss: 0.9652 - val_accuracy: 0.6604\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 233s 149ms/step - loss: 0.7945 - accuracy: 0.7202 - val_loss: 0.9673 - val_accuracy: 0.6676\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 233s 149ms/step - loss: 0.7453 - accuracy: 0.7389 - val_loss: 0.9416 - val_accuracy: 0.6739\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.6898 - accuracy: 0.7565 - val_loss: 0.9363 - val_accuracy: 0.6758\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 232s 149ms/step - loss: 0.6479 - accuracy: 0.7704 - val_loss: 0.9242 - val_accuracy: 0.6834\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 233s 149ms/step - loss: 0.5900 - accuracy: 0.7930 - val_loss: 0.9377 - val_accuracy: 0.6858\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 0.5602 - accuracy: 0.8012 - val_loss: 0.9332 - val_accuracy: 0.6892\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 231s 148ms/step - loss: 0.5206 - accuracy: 0.8170 - val_loss: 0.9502 - val_accuracy: 0.6842\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 0.4853 - accuracy: 0.8282 - val_loss: 0.9504 - val_accuracy: 0.6912\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 231s 147ms/step - loss: 0.4509 - accuracy: 0.8430 - val_loss: 0.9654 - val_accuracy: 0.6895\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 230s 147ms/step - loss: 0.4354 - accuracy: 0.8501 - val_loss: 0.9796 - val_accuracy: 0.6940\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.4041 - accuracy: 0.8567 - val_loss: 0.9847 - val_accuracy: 0.6922\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.3800 - accuracy: 0.8682 - val_loss: 0.9948 - val_accuracy: 0.6984\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 231s 148ms/step - loss: 0.3631 - accuracy: 0.8713 - val_loss: 1.0146 - val_accuracy: 0.6947\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 231s 148ms/step - loss: 0.3434 - accuracy: 0.8802 - val_loss: 1.0216 - val_accuracy: 0.6948\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.3335 - accuracy: 0.8848 - val_loss: 1.0274 - val_accuracy: 0.6985\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 0.3119 - accuracy: 0.8921 - val_loss: 1.0236 - val_accuracy: 0.6987\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 234s 150ms/step - loss: 0.2917 - accuracy: 0.8950 - val_loss: 1.0402 - val_accuracy: 0.7001\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 233s 149ms/step - loss: 0.2839 - accuracy: 0.9007 - val_loss: 1.0449 - val_accuracy: 0.6994\n",
            "Accuracy: 69.94%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}